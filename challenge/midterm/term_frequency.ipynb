{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "880d91a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----TF dictionary-----\n",
      "{'dog': 1, 'in': 1, 'gold': 1, 'lazy': 1, 'all': 1, 'read': 1, 'of': 2, 'brown': 1, 'jumps': 1, 'journey': 1, 'with': 1, 'middle': 1, 'lies': 1, 'the': 3, 'opportunity': 1, 'glitters': 1, 'step': 1, 'she': 1, 'books': 1, 'is': 1, 'over': 1, 'not': 1, 'difficulty': 1, 'to': 1, 'fox': 1, 'a': 3, 'likes': 1, 'single': 1, 'quick': 1, 'miles': 1, 'thousand': 1, 'begins': 1, 'that': 1}\n",
      "-----Top-3 TF terms-----\n",
      "1 the 3\n",
      "2 a 3\n",
      "3 of 2\n"
     ]
    }
   ],
   "source": [
    "import operator\n",
    "\n",
    "# 주어진 문장들\n",
    "sentences = [\n",
    "    \"The quick brown fox jumps over the lazy dog.\",\n",
    "    \"A journey of a thousand miles begins with a single step.\",\n",
    "    \"All that glitters is not gold.\",    \n",
    "    \"In the middle of difficulty lies opportunity.\",\n",
    "    \"She likes to read books.\"\n",
    "]\n",
    "\n",
    "# 문장을 정리하고 단어로 분할하는 함수\n",
    "def clean_and_split(sentence):\n",
    "    # 구두점을 제거하고 소문자로 변환\n",
    "    return sentence.replace('.', '').lower().split()\n",
    "\n",
    "# 모든 고유 단어를 저장할 집합을 초기화\n",
    "total_terms = set()\n",
    "\n",
    "# 문장들을 토큰화하고 정리\n",
    "for sentence in sentences:\n",
    "    # 정리하고 분할된 단어들을 total_terms 집합에 추가\n",
    "    total_terms.update(clean_and_split(sentence))\n",
    "\n",
    "# 각 토큰의 빈도를 저장할 딕셔너리 초기화\n",
    "term_frequency_dict = {}\n",
    "\n",
    "# total_terms 집합에 있는 각 토큰의 빈도를 계산\n",
    "for term in total_terms:\n",
    "    # 모든 문장에서 해당 토큰의 빈도를 계산\n",
    "    term_frequency_dict[term] = sum(clean_and_split(sentence).count(term) for sentence in sentences)\n",
    "\n",
    "# 빈도 사전을 출력\n",
    "print(\"-----TF dictionary-----\")\n",
    "print(term_frequency_dict)\n",
    "\n",
    "# 가장 높은 빈도를 가진 상위 3개의 토큰을 출력\n",
    "print(\"-----Top-3 TF terms-----\")\n",
    "# term_frequency_dict를 빈도수 기준 내림차순으로 정렬\n",
    "sorted_terms = sorted(term_frequency_dict.items(), key=operator.itemgetter(1), reverse=True)\n",
    "\n",
    "# 상위 3개의 토큰을 출력\n",
    "for i in range(3):\n",
    "    term, freq = sorted_terms[i]\n",
    "    print(f\"{i+1} {term} {freq}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7390e7ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
